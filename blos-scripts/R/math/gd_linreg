#!/usr/bin/env Rscript

args <- commandArgs(trailingOnly = TRUE)
args_contains <- function(str){
  for( a in args ){
    if( a == str ) return (TRUE)
  }
  return (FALSE)
}

data <- read.table( file("stdin"), sep=",", header=TRUE)
# now you can read data$x and data$y


m <- nrow(data)
datay <- data[2]^1
datax <- data[3]^1

# define the gradient function dJ/dtheata: 1/m * (h(x)-y))*x where h(x) = x*theta
# in matrix form this is as follows:
grad <- function(x, y, theta) {
  gradient <- (1/m)* (t(x) %*% ((x %*% t(theta)) - y))
  
  if( args_contains("-plot") ){

    if( args_contains("-all-theta")){
       write( paste(theta[1], theta[2],sep=" ") , stdout())
       abline( theta, col = "#C00000")
    }
  }
  return(t(gradient))
}


# define gradient descent update algorithm
grad.descent <- function(x, y, maxit){
    theta <- matrix(c(0, 0), nrow=1) # Initialize the parameters
 
    alpha = .05 # set learning rate
    for (i in 1:maxit) {
      theta <- theta - alpha  * grad(x, y, theta)   
    }
 return(theta)
}

x <- as.matrix( cbind( datax^0, datax^1 ) )
y <- as.matrix( datay )


if( args_contains("-plot") ){
 plot( datax^1, datay^1  )
}


# results without feature scaling
result <- grad.descent(x,y,200)
x0 <- result[1]
x1 <- result[2]
fm <- c(x0,x1)

write( paste(x0,x1,sep=" ") , stdout())



if( args_contains("-plot") ){
 abline( fm, col = "red")
 title(main="Show linear function: a+b*x", sub=paste(c("a=",toString(fm[0]),"b=",toString(fm[1])), collapse = ' '))
}
